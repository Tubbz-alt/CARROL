\section{Introduction}

Super resolution is the problem of “adding more pixels” in an image. To elaborate upon that, super resolution is a class of techniques to generate extra pixels in an image by extrapolating data from the picture as a whole. Currently, most techniques attempt to solve this problem by mathematically analysing an area and extrapolating the trends to intelligently guess what the values of the pixels would be at a higher resolution. We are interested in exploring deeper into Generative Adversarial Networks (GANs), which is a type of solution to the super resolution problem. GANs are the technique of using two deep neural networks to generate statistically accurate data points. In the application of super resolution, GANs treat pixels as the sample space, and try to infer the value of new pixels from that. However, most GANs currently solve the problem by just looking at pixel data, shapes, and other visual data found in the pictures. We are interested in seeing how “context” affects GANs’ performance. We want to see how adding metadata that is not necessarily apparent from the mathematical pixel data affects the GANs’ improvement in enhancing a photo, as well as GANs’ improvement in the range of photos that it can enhance.
