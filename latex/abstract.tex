\begin{abstract}
We addressed the classic computer vision problem of super-resolution. Most
	modern methods of super-resolution have achieved very impressive results with
	scaling factors of around 2-4x when using generative adversarial networks(GAN)
	on the entirety of single images. Other methods have been known to produce
	high pixels-to-signals noise ratio(PSNR) values. However, these methods donâ€™t
	necessarily account for the perceptual features of the objects. This leads to
	certain distortions while converting these images to super-resolution. This
	paper proposes an alternative approach to conducting super resolution on
	images. The algorithm is set up to focus on the important parts of the image
	that are deemed valuable to a human viewer. This is done by extracting those
	subjects from the image and running a class-conditional super-resolution GAN
	(SRCGAN) on it. Our model, trained on a custom dataset generated from an open
	source mp4 video, was able to produce images where the important subjects were
	more emphasized in the image. This was done to account for the fact that the
	segmentation model we are using is limited to certain types of classes. The
	fidelity of the generated images is tested by using PSNR against the ground
	truth.
\end{abstract}
